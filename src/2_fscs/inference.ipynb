{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference for an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 906 µs (started: 2024-07-13 20:17:57 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.2 s (started: 2024-07-13 20:16:21 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision.utils import save_image\n",
    "from net import MaskGenerator, ResiduePredictor\n",
    "from mydataset import MyDataset\n",
    "import cv2\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'manual_color_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m path_residue_predictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m run_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/residue_predictor.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_primary_color \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m7\u001b[39m:\n\u001b[0;32m---> 50\u001b[0m     manual_colors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mmanual_color_0\u001b[49m, manual_color_1, manual_color_2, manual_color_3,\\\n\u001b[1;32m     51\u001b[0m                                                manual_color_4, manual_color_5, manual_color_6]) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m num_primary_color \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m6\u001b[39m:\n\u001b[1;32m     53\u001b[0m     manual_colors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([manual_color_0, manual_color_1, manual_color_2, manual_color_3,\\\n\u001b[1;32m     54\u001b[0m                                                manual_color_4, manual_color_5]) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'manual_color_0' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 393 ms (started: 2024-07-13 20:16:42 +08:00)\n"
     ]
    }
   ],
   "source": [
    "#### User inputs\n",
    "\n",
    "run_name = 'sample'\n",
    "num_primary_color = 7 \n",
    "# num_primary_color = 6 \n",
    "csv_path = 'my_test.csv' # なんでも良い．後方でパスを置き換えるから\n",
    "resize_scale_factor = 1\n",
    "\n",
    "boost_scale = 1.7\n",
    "bound_flag = True\n",
    "\n",
    "# image name and palette color values\n",
    "\n",
    "### k-means\n",
    "# img_name = 'bluebird.png'; manual_color_0 = [254, 254, 254]; manual_color_1 = [119, 135, 160]; manual_color_2 = [189, 203, 219]; manual_color_3 = [71, 68, 70]; manual_color_4 = [220, 129, 91]; manual_color_5 = [149, 165, 188]; manual_color_6 = [246, 203, 154];\n",
    "# img_name = 'human.png'; manual_color_0 = [64, 59, 54]; manual_color_1 = [214, 197, 177]; manual_color_2 = [138, 131, 125]; manual_color_3 = [247, 237, 229]; manual_color_4 = [100, 94, 88]; manual_color_5 = [32, 28, 25]; manual_color_6 = [165, 158, 151];\n",
    "# img_name = 'lotus.png'; manual_color_0 = [16, 15, 14]; manual_color_1 = [179, 179, 178]; manual_color_2 = [65, 62, 56]; manual_color_3 = [207, 207, 206]; manual_color_4 = [126, 113, 96]; manual_color_5 = [132, 28, 43]; manual_color_6 = [154, 153, 151]; \n",
    "# img_name = 'rooster.png'; manual_color_0 = [250, 240, 234]; manual_color_1 = [34, 31, 30]; manual_color_2 = [112, 114, 114]; manual_color_3 = [72, 71, 70]; manual_color_4 = [157, 32, 55]; manual_color_5 = [180, 118, 98]; manual_color_6 = [196, 166, 153];\n",
    "# img_name = 'rosemaling.png'; manual_color_0 = [50, 64, 61]; manual_color_1 = [253, 253, 246]; manual_color_2 = [222, 144, 59]; manual_color_3 = [131, 151, 144]; manual_color_4 = [90, 108, 95]; manual_color_5 = [27, 22, 16]; manual_color_6 = [205, 204, 185];\n",
    "\n",
    "# img_name = 'Kim_Jisoo.jpg'; manual_color_0 = [175, 202, 211]; manual_color_1 = [28, 24, 23]; manual_color_2 = [211, 166, 151]; manual_color_3 = [115, 145, 145]; manual_color_4 = [229, 214, 205]; manual_color_5 = [174, 117, 90]; manual_color_6 = [89, 53, 43]; \n",
    "\n",
    "### octree\n",
    "# img_name = 'bluebird.png'; manual_color_0 = [254, 254, 254]; manual_color_1 = [148, 157, 173]; manual_color_2 = [157, 176, 204]; manual_color_3 = [87, 85, 88]; manual_color_4 = [246, 210, 167]; manual_color_5 = [110, 138, 174]; manual_color_6 = [181, 199, 221];\n",
    "# img_name = 'human.png'; manual_color_0 = [245, 236, 227]; manual_color_1 = [162, 155, 148]; manual_color_2 = [38, 34, 31]; manual_color_3 = [99, 93, 87]; manual_color_4 = [215, 197, 175]; manual_color_5 = [138, 131, 124]; manual_color_6 = [203, 187, 170];\n",
    "# img_name = 'lotus.png'; manual_color_0 = [206, 207, 206]; manual_color_1 = [169, 169, 168]; manual_color_2 = [57, 51, 48]; manual_color_3 = [152, 65, 74]; manual_color_4 = [156, 143, 91]; manual_color_5 = [190, 192, 190]; manual_color_6 = [190, 192, 192];\n",
    "# img_name = 'rooster.png'; manual_color_0 = [249, 239, 233]; manual_color_1 = [61, 59, 59]; manual_color_2 = [164, 74, 77]; manual_color_3 = [155, 155, 152]; manual_color_4 = [180, 139, 112]; manual_color_5 = [219, 165, 151]; manual_color_6 = [100, 119, 132];\n",
    "# img_name = 'rosemaling.png'; manual_color_0 = [251, 251, 244]; manual_color_1 = [69, 80, 72]; manual_color_2 = [218, 152, 69]; manual_color_3 = [156, 166, 160]; manual_color_4 = [173, 107, 49]; manual_color_5 = [114, 139, 138]; manual_color_6 = [232, 209, 167];\n",
    "\n",
    "\n",
    "# img_name = 'apple.jpg'; manual_color_0 = [253, 253, 254]; manual_color_1 = [203, 194, 170]; manual_color_2 = [83, 17, 22]; manual_color_3 = [205, 118, 4]; manual_color_4 = [220, 222, 11]; manual_color_5 = [155, 24, 10]; manual_color_6 = [171, 75, 67]; \n",
    "#img_name = 'boat.png'; manual_color_0 = [25, 21, 16]; manual_color_1 = [153, 155, 163]; manual_color_2 = [177,189,206]; manual_color_3 = [94, 89, 88]; manual_color_4 = [213, 215, 221]; manual_color_5 = [85,26,20]; manual_color_6 = [160,217,214]; \n",
    "#img_name = 'buildings.png'; manual_color_0 = [59, 66, 80]; manual_color_1 = [12, 12, 11]; manual_color_2 = [65, 56, 43]; manual_color_3 = [78, 92, 120]; manual_color_4 = [223, 192, 124]; manual_color_5 = [128, 102, 63]; manual_color_6 = [36, 36, 33]; \n",
    "#img_name = 'castle.jpg'; manual_color_0 = [60, 81, 116]; manual_color_1 = [175, 198, 215]; manual_color_2 = [0, 0, 0]; manual_color_3 = [114, 149, 185]; manual_color_4 = [142, 172, 198]; manual_color_5 = [92, 116, 149]; manual_color_6 = [226, 221, 222]; \n",
    "#img_name = 'girls.png'; manual_color_0 = [125, 116, 105]; manual_color_1 = [155, 162, 191]; manual_color_2 = [52, 60, 39]; manual_color_3 = [87, 120, 196]; manual_color_4 = [87, 107, 56]; manual_color_5 = [19, 26, 10]; manual_color_6 = [183,187,209]; \n",
    "#img_name = 'rowboat1.png'; manual_color_2 = [175, 77, 13]; manual_color_1 = [51, 45, 39]; manual_color_0 = [93, 89, 90]; manual_color_6 = [245, 141, 84]; manual_color_4 = [14, 13, 7]; manual_color_5 = [62, 71, 74]; manual_color_3 = [158,153,157]; \n",
    "#img_name = 'scrooge.png'; manual_color_0 = [254, 254, 254]; manual_color_1 = [78, 71, 65]; manual_color_2 = [211, 182, 135]; manual_color_3 = [165, 127, 100]; manual_color_4 = [40, 38, 34]; manual_color_5 = [112, 45, 31]; manual_color_6 = [177, 57, 35]; \n",
    "#img_name = 'turquoise.png'; manual_color_0 = [86, 59, 67]; manual_color_1 = [121, 132, 148]; manual_color_2 = [228, 186, 156]; manual_color_3 = [53, 35, 34]; manual_color_4 = [190, 135, 122]; manual_color_5 = [94, 152, 154]; manual_color_6 = [254,229,216]; \n",
    "#img_name = 'orange.png'; manual_color_0 = [79, 81, 59]; manual_color_1 = [112, 117, 105]; manual_color_2 = [137, 92, 41]; manual_color_3 = [201,214,197]; manual_color_4 = [42, 53, 49]; manual_color_5 = [168, 130, 40]; manual_color_6 = [114, 60, 31]; \n",
    "\n",
    "####\n",
    "\n",
    "img_path = '../myInput/' + img_name\n",
    "# img_path = '../dataset/test/' + img_name\n",
    "\n",
    "path_mask_generator = 'results/' + run_name + '/mask_generator.pth'\n",
    "path_residue_predictor = 'results/' + run_name + '/residue_predictor.pth'\n",
    "\n",
    "if num_primary_color == 7:\n",
    "    manual_colors = np.array([manual_color_0, manual_color_1, manual_color_2, manual_color_3,\\\n",
    "                                               manual_color_4, manual_color_5, manual_color_6]) /255\n",
    "elif num_primary_color == 6:\n",
    "    manual_colors = np.array([manual_color_0, manual_color_1, manual_color_2, manual_color_3,\\\n",
    "                                               manual_color_4, manual_color_5]) /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 117 ms (started: 2024-07-10 17:00:51 +08:00)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.makedirs('results/%s/%s' % (run_name, img_name))\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResiduePredictor(\n",
       "  (conv1): Conv2d(31, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (conv2): Conv2d(62, 124, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (conv3): Conv2d(124, 248, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (deconv1): ConvTranspose2d(248, 124, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "  (deconv2): ConvTranspose2d(248, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "  (deconv3): ConvTranspose2d(124, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "  (conv4): Conv2d(65, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(31, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm2d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm2d(248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bnde1): BatchNorm2d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bnde2): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bnde3): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn4): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.54 s (started: 2024-07-10 17:00:51 +08:00)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = MyDataset(csv_path, num_primary_color, mode='test')\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "# define model\n",
    "mask_generator = MaskGenerator(num_primary_color).to(device)\n",
    "residue_predictor = ResiduePredictor(num_primary_color).to(device)\n",
    "\n",
    "\n",
    "# load params\n",
    "mask_generator.load_state_dict(torch.load(path_mask_generator))\n",
    "residue_predictor.load_state_dict(torch.load(path_residue_predictor))\n",
    "\n",
    "\n",
    "# eval mode\n",
    "mask_generator.eval()\n",
    "residue_predictor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 495 ms (started: 2024-07-10 17:00:52 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 必要な関数を定義する\n",
    "\n",
    "def replace_color(primary_color_layers, manual_colors):\n",
    "    temp_primary_color_layers = primary_color_layers.clone()\n",
    "    for layer in range(len(manual_colors)):\n",
    "        for color in range(3):\n",
    "                temp_primary_color_layers[:,layer,color,:,:].fill_(manual_colors[layer][color])\n",
    "    return temp_primary_color_layers\n",
    "\n",
    "\n",
    "def cut_edge(target_img):\n",
    "    #print(target_img.size())\n",
    "    target_img = F.interpolate(target_img, scale_factor=resize_scale_factor, mode='area')\n",
    "    #print(target_img.size())\n",
    "    h = target_img.size(2)\n",
    "    w = target_img.size(3)\n",
    "    h = h - (h % 8)\n",
    "    w = w - (w % 8)\n",
    "    target_img = target_img[:,:,:h,:w]\n",
    "    #print(target_img.size())\n",
    "    return target_img\n",
    "\n",
    "def alpha_normalize(alpha_layers):\n",
    "    # constraint (sum = 1)\n",
    "    # layersの状態で受け取り，その形で返す. bn, ln, 1, h, w\n",
    "    return alpha_layers / (alpha_layers.sum(dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "def read_backimage():\n",
    "    img = cv2.imread('../dataset/backimage.jpg')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.transpose((2,0,1))\n",
    "    img = img/255\n",
    "    img = torch.from_numpy(img.astype(np.float32))\n",
    "\n",
    "    return img.view(1,3,256,256).to(device)\n",
    "\n",
    "backimage = read_backimage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 146 ms (started: 2024-07-10 17:00:53 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from guided_filter_pytorch.guided_filter import GuidedFilter\n",
    "\n",
    "def proc_guidedfilter(alpha_layers, guide_img):\n",
    "    # guide_imgは， 1chのモノクロに変換\n",
    "    # target_imgを使う． bn, 3, h, w\n",
    "    guide_img = (guide_img[:, 0, :, :]*0.299 + guide_img[:, 1, :, :]*0.587 + guide_img[:, 2, :, :]*0.114).unsqueeze(1)\n",
    "        \n",
    "    # lnのそれぞれに対してguideg filterを実行\n",
    "    for i in range(alpha_layers.size(1)): # bn, ln, 1, h, w\n",
    "        # layerは，bn, 1, h, w\n",
    "        layer = alpha_layers[:, i, :, :, :]\n",
    "        \n",
    "        processed_layer = GuidedFilter(3, 1*1e-6)(guide_img, layer)\n",
    "        \n",
    "        # processed_layer = torch.where(processed_layer > 0.05, processed_layer, torch.tensor(0))\n",
    "        # print('processed_layer', processed_layer)\n",
    "        \n",
    "        # レイヤーごとの結果をまとめてlayersの形に戻す (bn, ln, 1, h, w)\n",
    "        if i == 0: \n",
    "            processed_alpha_layers = processed_layer.unsqueeze(1)\n",
    "            # print(i, processed_alpha_layers.shape)\n",
    "        else:\n",
    "            processed_alpha_layers = torch.cat((processed_alpha_layers, processed_layer.unsqueeze(1)), dim=1)\n",
    "            # print(i, processed_alpha_layers.shape)\n",
    "    \n",
    "    return processed_alpha_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 70.9 ms (started: 2024-07-10 17:00:53 +08:00)\n"
     ]
    }
   ],
   "source": [
    "target_layer_number = [0, 1] # マスクで操作するレイヤーの番号\n",
    "mask_path = '../myInput/mask/rosemaling_up_mask.png'\n",
    "\n",
    "\n",
    "## Define functions for mask operation.\n",
    "# マスクを受け取る関数\n",
    "# target_layer_numberが冗長なレイヤーの番号（２つ）のリスト．これらのレイヤーに操作を加える\n",
    "\n",
    "def load_mask(mask_path):\n",
    "    mask = cv2.imread(mask_path, 0) #白黒で読み込み\n",
    "    mask[mask<128] = 0.\n",
    "    mask[mask >= 128] = 1.\n",
    "    # tensorに変換する\n",
    "    mask = torch.from_numpy(mask).unsqueeze(0).unsqueeze(0).float().cuda()\n",
    "    \n",
    "    return mask\n",
    "        \n",
    "\n",
    "def mask_operate(alpha_layers, target_layer_number, mask_path):\n",
    "    layer_A = alpha_layers[:, target_layer_number[0], :, :, :]\n",
    "    layer_B = alpha_layers[:, target_layer_number[1], :, :, :]\n",
    "    \n",
    "    layer_AB = layer_A + layer_B    \n",
    "    \n",
    "    mask = load_mask(mask_path)\n",
    "    \n",
    "    mask = cut_edge(mask)\n",
    "    \n",
    "    layer_A = layer_AB * mask\n",
    "    layer_B = layer_AB * (1. - mask)\n",
    "    \n",
    "    return_alpha_layers = alpha_layers.clone()\n",
    "    return_alpha_layers[:, target_layer_number[0], :, :, :] = layer_A\n",
    "    return_alpha_layers[:, target_layer_number[1], :, :, :] = layer_B\n",
    "    \n",
    "    return return_alpha_layers\n",
    "\n",
    "\n",
    "def my_mask_operate(alpha_layers, mask_path):\n",
    "    return_alpha_layers = alpha_layers.clone()\n",
    "    \n",
    "    for i in range(num_primary_color):\n",
    "        layer = alpha_layers[:, i, :, :, :]\n",
    "        \n",
    "        mask = load_mask(mask_path)\n",
    "        \n",
    "        mask = cut_edge(mask)\n",
    "\n",
    "        layer = layer * mask\n",
    "        \n",
    "        return_alpha_layers[:, i, :, :, :] = layer\n",
    "        \n",
    "    return return_alpha_layers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 124 ms (started: 2024-07-10 17:00:53 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# datasetにある画像のパスを置き換えてしまう\n",
    "test_dataset.imgs_path[0] = img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start!\n",
      "0 0\n",
      "img # 0\n",
      "residue torch.Size([1, 7, 3, 1112, 800])\n",
      "8.293265104293823\n",
      "Saved to results/sample/rosemaling_up.png/...\n",
      "time: 12.7 s (started: 2024-07-10 17:00:53 +08:00)\n"
     ]
    }
   ],
   "source": [
    "print('Start!')\n",
    "img_number = 0\n",
    "\n",
    "\n",
    "mean_estimation_time = 0\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (target_img, primary_color_layers) in enumerate(test_loader):\n",
    "        print(batch_idx, img_number)\n",
    "        if batch_idx != img_number:\n",
    "            print('Skip ', batch_idx)\n",
    "            continue\n",
    "        print('img #', batch_idx)\n",
    "        target_img = cut_edge(target_img)   # resize the image and make sure the H & W can be divided by 8  \n",
    "        target_img = target_img.to(device) # bn, 3ch, h, w\n",
    "        primary_color_layers = primary_color_layers.to(device) # primary_color_layers #out: (bn, ln, 3, h, w)\n",
    "        #primary_color_layers = color_regresser(target_img)\n",
    "        ##\n",
    "        ##\n",
    "        primary_color_layers = replace_color(primary_color_layers, manual_colors) #ここ\n",
    "        ##\n",
    "        #print(primary_color_layers.mean())\n",
    "        #print(primary_color_layers.size())\n",
    "        start_time = time.time()\n",
    "        primary_color_pack = primary_color_layers.view(primary_color_layers.size(0), -1 , primary_color_layers.size(3), primary_color_layers.size(4))\n",
    "\n",
    "        import torch\n",
    "        import matplotlib.pyplot as plt\n",
    "        from PIL import Image\n",
    "        \n",
    "        # image1_tensor= primary_color_layers[0][0]\n",
    "        # print(image1_tensor.shape)\n",
    "        # out = image1_tensor.permute(2, 1, 0).detach().cpu().numpy()\n",
    "        # arr_ = np.squeeze(out)\n",
    "        # plt.imshow(arr_)\n",
    "        # plt.show()\n",
    "        \n",
    "        primary_color_pack = cut_edge(primary_color_pack)\n",
    "        primary_color_layers = primary_color_pack.view(primary_color_pack.size(0),-1,3,primary_color_pack.size(2), primary_color_pack.size(3))\n",
    "        pred_alpha_layers_pack = mask_generator(target_img, primary_color_pack)\n",
    "        pred_alpha_layers = pred_alpha_layers_pack.view(target_img.size(0), -1, 1, target_img.size(2), target_img.size(3))\n",
    "        \n",
    "        # print('primary_color_layers', primary_color_layers.shape)\n",
    "        # print('primary_color_layers', primary_color_layers)\n",
    "        # print('pred_alpha_layers', pred_alpha_layers.shape)\n",
    "        \n",
    "        ## Alpha Layer Proccessing\n",
    "        processed_alpha_layers = alpha_normalize(pred_alpha_layers) \n",
    "        # processed_alpha_layers = mask_operate(processed_alpha_layers, target_layer_number, mask_path) # Option\n",
    "        \n",
    "        processed_alpha_layers = my_mask_operate(processed_alpha_layers, mask_path)\n",
    "        \n",
    "        processed_alpha_layers = proc_guidedfilter(processed_alpha_layers, target_img) # Option\n",
    "        # processed_alpha_layers = alpha_normalize(processed_alpha_layers)  # Option\n",
    "        \n",
    "        # print('processed_alpha_layers', processed_alpha_layers.shape)\n",
    "        # print('processed_alpha_layers', processed_alpha_layers)\n",
    "        \n",
    "        ### my add\n",
    "        processed_alpha_layers *= boost_scale\n",
    "        if bound_flag:\n",
    "            processed_alpha_layers = torch.where(processed_alpha_layers > 1, torch.tensor(1), processed_alpha_layers)\n",
    "        \n",
    "            \n",
    "        # print('processed_alpha_layers_2', processed_alpha_layers.shape)\n",
    "        # print('processed_alpha_layers_2', processed_alpha_layers)\n",
    "        \n",
    "        ##\n",
    "        mono_color_layers = torch.cat((primary_color_layers, processed_alpha_layers), 2) #shape: bn, ln, 4, h, w\n",
    "        mono_color_layers_pack = mono_color_layers.view(target_img.size(0), -1 , target_img.size(2), target_img.size(3))\n",
    "        residue_pack  = residue_predictor(target_img, mono_color_layers_pack)\n",
    "        residue = residue_pack.view(target_img.size(0), -1, 3, target_img.size(2), target_img.size(3))\n",
    "        \n",
    "        print('residue', residue.shape)\n",
    "        # print('residue', residue)\n",
    "        \n",
    "        pred_unmixed_rgb_layers = torch.clamp((primary_color_layers + residue), min=0., max=1.0)\n",
    "        reconst_img = (pred_unmixed_rgb_layers * processed_alpha_layers).sum(dim=1)\n",
    "        # print('reconst_img', reconst_img[0][0][0][0])\n",
    "        \n",
    "        # print('pred_unmixed_rgb_layers', pred_unmixed_rgb_layers.shape)\n",
    "        # print('pred_unmixed_rgb_layers', pred_unmixed_rgb_layers)\n",
    "        # print('reconst_img', reconst_img.shape)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        estimation_time = end_time - start_time\n",
    "        print(estimation_time)\n",
    "        mean_estimation_time += estimation_time\n",
    "        \n",
    "        if True:\n",
    "            # batchsizeは１で計算されているはず．それぞれ保存する．\n",
    "            save_layer_number = 0\n",
    "            save_image(primary_color_layers[save_layer_number,:,:,:,:],\n",
    "                   'results/%s/%s/test' % (run_name, img_name) + '_img-%02d_primary_color_layers.png' % batch_idx)\n",
    "            save_image(reconst_img[save_layer_number,:,:,:].unsqueeze(0),\n",
    "                   'results/%s/%s/test' % (run_name, img_name)  + '_img-%02d_reconst_img.png' % batch_idx)\n",
    "            save_image(target_img[save_layer_number,:,:,:].unsqueeze(0),\n",
    "                   'results/%s/%s/test' % (run_name, img_name)  + '_img-%02d_target_img.png' % batch_idx)\n",
    "\n",
    "            # RGBAの４chのpngとして保存する\n",
    "            RGBA_layers = torch.cat((pred_unmixed_rgb_layers, processed_alpha_layers), dim=2) # out: bn, ln, 4, h, w\n",
    "            # test ではバッチサイズが１なので，bn部分をなくす\n",
    "            RGBA_layers = RGBA_layers[0] # ln, 4. h, w\n",
    "            \n",
    "            # print('RGBA_layers', RGBA_layers[0][0][0][0])\n",
    "            \n",
    "            # ln ごとに結果を保存する\n",
    "            # for i in range(len(RGBA_layers)):\n",
    "            #     save_image(RGBA_layers[i, :, :, :], 'results/%s/%s/img-%02d_layer-%02d.png' % (run_name, img_name, batch_idx, i) )\n",
    "            # print('Saved to results/%s/%s/...' % (run_name, img_name))\n",
    "\n",
    "            for i in range(len(RGBA_layers)):\n",
    "                save_image(RGBA_layers[i, :, :, :], 'results/%s/%s/img-%02d_layer-%02d.png' % (run_name, img_name, batch_idx, i) )\n",
    "                \n",
    "                # layer = cv2.imread('results/%s/%s/img-%02d_layer-%02d.png' % (run_name, img_name, batch_idx, i), cv2.IMREAD_UNCHANGED)\n",
    "                # im1 = Image.open('results/%s/%s/img-%02d_layer-%02d.png' % (run_name, img_name, batch_idx, i))\n",
    "                # r, g, b ,a = im1.split()\n",
    "                # output = cv2.add(layer, layer)\n",
    "                # cv2.imwrite('output.png', output)\n",
    "                \n",
    "            print('Saved to results/%s/%s/...' % (run_name, img_name))\n",
    "            \n",
    "            \n",
    "        if False:\n",
    "            ### mono_colorの分も保存する ###\n",
    "            # RGBAの４chのpngとして保存する\n",
    "            mono_RGBA_layers = torch.cat((primary_color_layers, processed_alpha_layers), dim=2) # out: bn, ln, 4, h, w\n",
    "            # test ではバッチサイズが１なので，bn部分をなくす\n",
    "            mono_RGBA_layers = mono_RGBA_layers[0] # ln, 4. h, w\n",
    "            # ln ごとに結果を保存する\n",
    "            for i in range(len(mono_RGBA_layers)):\n",
    "                save_image(mono_RGBA_layers[i, :, :, :], 'results/%s/%s/mono_img-%02d_layer-%02d.png' % (run_name, img_name, batch_idx, i) )\n",
    "\n",
    "            save_image((primary_color_layers * processed_alpha_layers).sum(dim=1)[save_layer_number,:,:,:].unsqueeze(0),\n",
    "                   'results/%s/%s/test' % (run_name, img_name)  + '_mono_img-%02d_reconst_img.png' % batch_idx)   \n",
    "        \n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            break # debug用\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Appendix) Save alpha channel and RGB channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 943 ms (started: 2024-07-10 17:01:06 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 処理まえのアルファを保存\n",
    "for i in range(len(pred_alpha_layers[0])):\n",
    "            save_image(pred_alpha_layers[0,i, :, :, :], 'results/%s/%s/pred-alpha-00_layer-%02d.png' % (run_name, img_name, i) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 716 ms (started: 2024-07-10 17:01:07 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 処理後のアルファの保存 processed_alpha_layers\n",
    "for i in range(len(processed_alpha_layers[0])):\n",
    "            save_image(processed_alpha_layers[0,i, :, :, :], 'results/%s/%s/proc-alpha-00_layer-%02d.png' % (run_name, img_name, i) )\n",
    "            \n",
    "            # layer = cv2.imread('results/%s/%s/proc-alpha-00_layer-%02d.png' % (run_name, img_name, i))\n",
    "            # blur = cv2.GaussianBlur(layer, (35, 35), 0)\n",
    "            # cv2.imwrite('results/%s/%s/proc-alpha-00_layer-%02d.png' % (run_name, img_name, i), blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.78 s (started: 2024-07-10 17:01:08 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 処理後のRGBの保存\n",
    "for i in range(len(pred_unmixed_rgb_layers[0])):\n",
    "    save_image(pred_unmixed_rgb_layers[0,i, :, :, :], 'results/%s/%s/rgb-00_layer-%02d.png' % (run_name, img_name, i) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Appendix) K-means for culculating pallete colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gliamanti/myApps/anaconda3/envs/fscs/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:792: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 50.66555019  64.29837202  61.13479514 253.78197343 253.68230444\n",
      " 246.14292545 222.94169251 144.20676095  59.47394691 131.53153852\n",
      " 151.63623229 144.03804003  90.21575682 108.88050322  95.08211988\n",
      "  27.35528414  22.0957471   16.69362328 205.38064412 204.98463768\n",
      " 185.11964573]\n",
      "time: 8.5 s (started: 2024-07-13 20:23:10 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "### User inputs\n",
    "num_clusters = 7\n",
    "img_name = 'rosemaling.png'\n",
    "img_path = '../myInput/' + img_name\n",
    "# img_name = 'apple.jpg'\n",
    "# img_path = '../dataset/test/' + img_name\n",
    "\n",
    "###\n",
    "\n",
    "img = cv2.imread(img_path)[:, :, [2, 1, 0]]\n",
    "size = img.shape[:2]\n",
    "vec_img = img.reshape(-1, 3)\n",
    "model = KMeans(n_clusters=num_clusters, n_jobs=-1)\n",
    "pred = model.fit_predict(vec_img)\n",
    "pred_img = np.tile(pred.reshape(*size,1), (1,1,3))\n",
    "\n",
    "center = model.cluster_centers_.reshape(-1)\n",
    "print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_name = 'rosemaling.png'; manual_color_0 = [50, 64, 61]; manual_color_1 = [253, 253, 246]; manual_color_2 = [222, 144, 59]; manual_color_3 = [131, 151, 144]; manual_color_4 = [90, 108, 95]; manual_color_5 = [27, 22, 16]; manual_color_6 = [205, 204, 185]; time: 589 µs (started: 2024-07-13 20:23:19 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# Reshape for an input\n",
    "print('img_name = \\'%s\\';' % img_name, end=\" \")\n",
    "for k, i in enumerate(model.cluster_centers_):\n",
    "    print('manual_color_%d = [' % k + str(i[0].astype('int')) +', '+ str(i[1].astype('int'))+  ', '+ str(i[2].astype('int')) + '];', end=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
